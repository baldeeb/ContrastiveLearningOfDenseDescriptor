{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/baldeeb/Documents/Projects/ContrastiveLearningOfDenseDescriptor\n",
    "%cd /home/baldeeb/Documents/Projects/dense_descriptors_and_acf/ContrastiveLearningOfDenseDescriptor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch \n",
    "from addict import Dict\n",
    "from dataset import make_data_loader\n",
    "from models.dense_model import DenseModel\n",
    "from util.model_storage import load_dense_model\n",
    "\n",
    "# Read Config\n",
    "with open('configuration/train.yaml') as f: \n",
    "    cfg = Dict(yaml.safe_load(f))\n",
    "\n",
    "# Load model\n",
    "cfg.load_model_path = 'results/checkpoints_2022_01_11__17_03_25/models/2022_01_11__17_03_25_9_20500_final'\n",
    "model, optimizer = load_dense_model(cfg.load_model_path)\n",
    "\n",
    "# Dataloader\n",
    "dataloader = make_data_loader(split='train', args=cfg.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "def visualize(image, descriptor):\n",
    "    fig = plt.figure(); gs = fig.add_gridspec(1, 2); axs = gs.subplots()\n",
    "    image = image.permute(1,2,0).float()\n",
    "    descriptor = descriptor.permute(1,2,0).float()\n",
    "    axs[0].imshow(image.clone().detach().cpu())\n",
    "    axs[1].imshow(descriptor.clone().detach().cpu()) \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run model\n",
    "with torch.no_grad():\n",
    "    descriptors, images = None, None\n",
    "    itr, target = 0, 3\n",
    "    for im, batch in dataloader:\n",
    "        images = im.to(cfg.device)\n",
    "        descriptors = model(images)\n",
    "        visualize(images[0], descriptors[0])\n",
    "        visualize(images[1], descriptors[1])\n",
    "\n",
    "        if itr == target: break\n",
    "        itr = itr + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp config \n",
    "class cfg():\n",
    "    dataset = 'unreal_parts'\n",
    "    data_dir = '../simple_data'\n",
    "    image_type = 'RGB'\n",
    "    obj_class = 'mug'\n",
    "    n_pair = 0\n",
    "    n_nonpair_singleobj = 0 \n",
    "    n_nonpair_bg = 0\n",
    "    batch_size = 1\n",
    "    workers = 1\n",
    "\n",
    "    device = 'cuda:0'\n",
    "    # device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "## Load model\n",
    "file = '/home/baldeeb/Documents/Projects/ContrastiveLearningOfDenseDescriptor/temp/results_old/first_successful_run/model_checkpoints/13_09_2021__11_29_03_19_final'\n",
    "device = torch.device('cuda:0')\n",
    "state_dict = torch.load(file, map_location=device)\n",
    "backbone = deeplabv3_resnet50(num_classes=3).to(device)\n",
    "backbone.load_state_dict(state_dict['model_state_dict'])\n",
    "\n",
    "## Load data\n",
    "from dataset import make_data_loader\n",
    "dataloader = make_data_loader(split='train', args=cfg())\n",
    "\n",
    "## Run model\n",
    "descriptors, images = None, None\n",
    "for im, batch in dataloader:\n",
    "    images = im.to(device)\n",
    "    descriptors = backbone(images)['out']\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## De-Normalize\n",
    "data_mean, data_std = [0.5183, 0.5747, 0.7210], [0.3218, 0.3045, 0.2688]  # Unreal Progress Mugs\n",
    "im = images[0].clone().detach().cpu()\n",
    "im = im * torch.tensor(data_std).reshape(-1, 1, 1) + torch.tensor(data_mean).reshape(-1, 1, 1)\n",
    "d = descriptors[0].clone().detach().sigmoid().cpu()\n",
    "\n",
    "# print(descriptors.min(), descriptors.max(), descriptors.mean(), descriptors.std())\n",
    "\n",
    "## Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize(image, descriptor):\n",
    "    fig = plt.figure(); gs = fig.add_gridspec(1, 2); axs = gs.subplots()\n",
    "    image = image.permute(1,2,0).float()\n",
    "    descriptor = descriptor.permute(1,2,0).float()\n",
    "    axs[0].imshow(image)\n",
    "    axs[1].imshow(descriptor) \n",
    "    plt.show()\n",
    "\n",
    "visualize(im, d)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99ec159a32af17dfba3905522e87a76d2281d17d4ed25349b6aad653c2254f11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('acf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
